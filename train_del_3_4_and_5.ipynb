{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5c2771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saisr\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#model.py\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        My custom ResidualBlock\n",
    "\n",
    "        [input]\n",
    "        * in_channels  : input channel number\n",
    "        * out_channels : output channel number\n",
    "        * kernel_size  : kernel size\n",
    "        * stride       : stride size\n",
    "\n",
    "        [hint]\n",
    "        * See the instruction PDF for details\n",
    "        * Set the bias argument to False\n",
    "        \"\"\"\n",
    "        \n",
    "        ## Define all the layers\n",
    "        # ----- TODO -----\n",
    "\n",
    "        self.conv2d_1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size, stride, 1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv2d_2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size, 1, 1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, stride, 0),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.Relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "       \n",
    "        # ----- TODO -----\n",
    "        output = self.conv2d_1(x)\n",
    "        output1 = self.conv2d_2(output)\n",
    "        shortcut = self.shortcut(x)\n",
    "        output2 = shortcut + output1\n",
    "        output = self.Relu(output2)\n",
    "        conv_layer = output1\n",
    "        return output, conv_layer\n",
    "\n",
    "\n",
    "class MyResnet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        My custom ResNet.\n",
    "\n",
    "        [input]\n",
    "        * in_channels  : input channel number\n",
    "        * num_classes  : number of classes\n",
    "\n",
    "        [hint]\n",
    "        * See the instruction PDF for details\n",
    "        * Set the bias argument to False\n",
    "        \"\"\"\n",
    "        \n",
    "        ## Define all the layers\n",
    "        # ----- TODO -----\n",
    "\n",
    "        self.conv_initial = nn.Conv2d(in_channels=in_channels,\n",
    "                                      out_channels=64,\n",
    "                                      kernel_size=3,\n",
    "                                      stride = 1,\n",
    "                                      padding = 1)\n",
    "        \n",
    "        self.batch_norm_initial = nn.BatchNorm2d(num_features=64)\n",
    "        self.initial_Relu = nn.ReLU()\n",
    "\n",
    "        self.block1 = ResidualBlock(in_channels=64,\n",
    "                                    out_channels=128,\n",
    "                                    kernel_size=3,\n",
    "                                    stride =2)\n",
    "        \n",
    "        self.block2 = ResidualBlock(in_channels=128,\n",
    "                                    out_channels=256,\n",
    "                                    kernel_size=3,\n",
    "                                    stride=2)\n",
    "        \n",
    "        self.block3 = ResidualBlock(in_channels=256,\n",
    "                                    out_channels=512,\n",
    "                                    kernel_size=3,\n",
    "                                    stride=2)\n",
    "                \n",
    "        self.AvgPool_2d = nn.AvgPool2d(kernel_size=4)\n",
    "\n",
    "        self.Linear_1d = nn.Linear(512, out_features=num_classes)\n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "        #raise NotImplementedError\n",
    "\n",
    "\n",
    "    def forward(self, x, return_embed=False):\n",
    "        \"\"\"\n",
    "        Forward path.\n",
    "\n",
    "        [input]\n",
    "        * x             : input data\n",
    "        * return_embed  : whether return the feature map of the last conv layer or not\n",
    "\n",
    "        [output]\n",
    "        * output        : output data\n",
    "        * embedding     : the feature map after the last conv layer (optional)\n",
    "        \n",
    "        [hint]\n",
    "        * See the instruction PDF for network details\n",
    "        * You want to set return_embed to True if you are dealing with CAM\n",
    "        \"\"\"\n",
    "\n",
    "        # ----- TODO -----\n",
    "        output = self.conv_initial(x)\n",
    "        output = self.batch_norm_initial(output)\n",
    "        output = self.initial_Relu(output)\n",
    "        output, conv_layer = self.block1(output)\n",
    "        output, conv_layer = self.block2(output)\n",
    "        output, conv_layer = self.block3(output)\n",
    "        output = self.AvgPool_2d(output)\n",
    "        output = self.Flatten(output)\n",
    "        #print(output.shape)\n",
    "        output = self.Linear_1d(output)\n",
    "        output =  self.softmax(output)\n",
    "        \n",
    "        if return_embed == True:\n",
    "            return output, conv_layer\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "\n",
    "def init_weights_kaiming(m):\n",
    "\n",
    "    \"\"\"\n",
    "    Kaming initialization.\n",
    "\n",
    "    [input]\n",
    "    * m : torch.nn.Module\n",
    "\n",
    "    [hint]\n",
    "    * Refer to the course slides/recitations for more details\n",
    "    * Initialize the bias term in linear layer by a small constant, e.g., 0.01\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        # ----- TODO -----\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        # ----- TODO -----\n",
    "        nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.01)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # set model\n",
    "    net = MyResnet(in_channels=3, num_classes=10)\n",
    "    net.apply(init_weights_kaiming)\n",
    "    \n",
    "    # sanity check\n",
    "    input = torch.randn((64, 3, 32, 32), requires_grad=True)\n",
    "    output = net(input)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "684e964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.py\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "#from model import MyResnet, init_weights_kaiming\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f032b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4825be22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "LOAD DATASET: TRAIN/VAL | 50000/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saisr\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 0.42854\n",
      "val accuracy = 0.5108\n",
      "train accuracy = 0.56066\n",
      "val accuracy = 0.6122\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# set param\n",
    "setup_seed(18786)\n",
    "batch_size = 128\n",
    "num_epoch = 2\n",
    "lr = 1e-3\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Set model\n",
    "## Set the device to Cuda if needed\n",
    "## Initialize all the parameters\n",
    "# ----- TODO -----\n",
    "net = MyResnet()\n",
    "\n",
    "\n",
    "## Create the criterion and optimizer\n",
    "# ----- TODO -----\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params = net.parameters(), lr=lr)\n",
    "\n",
    "## Load dataset\n",
    "normalize_param = dict(\n",
    "    mean=[0.485, 0.456, 0.406], \n",
    "    std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)), \n",
    "    transforms.RandomHorizontalFlip(), transforms.ToTensor(), \n",
    "    transforms.Normalize(**normalize_param,inplace=True)\n",
    "    ])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(**normalize_param,inplace=True)\n",
    "    ])\n",
    "\n",
    "# ----- TODO -----\n",
    "trainset = torchvision.datasets.CIFAR10(root='handout/code/deliverable3-5',\n",
    "                                        train=True,\n",
    "                                        transform=train_transform,\n",
    "                                        download=True)\n",
    "trainloader = DataLoader(dataset=trainset, \n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "valset = torchvision.datasets.CIFAR10(root='handout/code/deliverable3-5',\n",
    "                                      train=False,\n",
    "                                      transform=val_transform,\n",
    "                                      download=True)\n",
    "valloader = DataLoader(valset, batch_size, False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "        'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(f\"LOAD DATASET: TRAIN/VAL | {len(trainset)}/{len(valset)}\")\n",
    "\n",
    "\n",
    "net.to(DEVICE)\n",
    "## Training and evaluation\n",
    "## Feel free to record the loss and accuracy numbers\n",
    "## Hint: you could separate the training and evaluation \n",
    "## process into 2 different functions for each epoch\n",
    "for epoch in range(num_epoch): \n",
    "\n",
    "    # ----- TODO -----\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_vals = 0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(inputs)\n",
    "        values, prediction_output = output.max(1)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct_vals = torch.eq(prediction_output, labels)\n",
    "        correct += torch.sum(correct_vals).item()\n",
    "        total_vals+=labels.size(0)\n",
    "        total_loss+=loss.item()\n",
    "\n",
    "    val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_vals_val = 0\n",
    "    for i, data in enumerate(valloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        output = net(inputs)\n",
    "        vals, preds = output.max(1)\n",
    "        true = torch.eq(preds, labels)\n",
    "        correct_val += torch.sum(true).item()\n",
    "        total_vals_val+=labels.size(0)\n",
    "\n",
    "    print(f'train accuracy = {correct/total_vals}')\n",
    "    print(f'val accuracy = {correct_val/total_vals_val}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "610a2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAM(net, inputs, labels, idx):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculate the CAM.\n",
    "\n",
    "    [input]\n",
    "    * net     : network\n",
    "    * inputs  : input data\n",
    "    * labels  : label data\n",
    "    * idx     : the index of the chosen image in a minibatch, range: [0, batch_size-1]\n",
    "\n",
    "    [output]\n",
    "    * cam_img : CAM result\n",
    "    * img     : raw image\n",
    "\n",
    "    [hint]\n",
    "    * Inputs and labels are in a minibatch form\n",
    "    * You can choose one images from them for CAM by idx.\n",
    "    \"\"\"\n",
    "    \n",
    "    net.eval()\n",
    "    net.to(DEVICE)\n",
    "    output, conv_layer_final = net(inputs, return_embed = True)\n",
    "    \n",
    "    gap = nn.AvgPool2d(conv_layer_final.size()[2])\n",
    "    conv_gap = gap(conv_layer_final) #performed global average pooling on the images\n",
    "    conv_gap = conv_gap.view(conv_gap.size(0), -1) \n",
    "    \n",
    "    output = net.Linear_1d(conv_gap)\n",
    "    weights = net.Linear_1d.weight #weights for the linear layer\n",
    "    \n",
    "    #n=512, N=10, batch_size = 128\n",
    "    cam = torch.matmul(conv_gap, weights.T)\n",
    "    cam_idx = cam[idx]\n",
    "    print(cam_idx.size())\n",
    "    return cam_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c394cbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"cam = F.interpolate(cam_idx.unsqueeze(0).unsqueeze(0), size=(32,32), \\n                            mode='bilinear', align_corners=False)\\nimg = inputs[0].permute(1, 2, 0).cpu().numpy()\\nax1.imshow(img)\\nax1.axis('off')\\nax1.set_title('Original Image')\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "## Fetch the test image for CAM\n",
    "dataiter = iter(valloader)\n",
    "inputs, labels = next(dataiter)\n",
    "inputs, label = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "cam_idx = CAM(net, inputs, labels, idx=0) # idx could be changed\n",
    "\n",
    "\n",
    "\n",
    "## Visualization\n",
    "## Plot the loss and acc curves\n",
    "# ----- TODO -----\n",
    "\n",
    "\n",
    "## Plot the CAM resuls as well as raw images\n",
    "## Hint: You will want to resize the CAM result.\n",
    "# ----- TODO -----\n",
    "'''cam = F.interpolate(cam_idx.unsqueeze(0).unsqueeze(0), size=(32,32), \n",
    "                            mode='bilinear', align_corners=False)\n",
    "img = inputs[0].permute(1, 2, 0).cpu().numpy()\n",
    "ax1.imshow(img)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Original Image')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0475c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
